{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    xrange = xrange\n",
    "except:\n",
    "    xrange = range\n",
    "from PIL import ImageGrab\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import random\n",
    "import io\n",
    "from lib.getkeys import key_check\n",
    "from lib.reinforcement import Qnetwork,updateTarget,updateTargetGraph\n",
    "from lib.SQL import SQLCalls\n",
    "from sys import stdout\n",
    "import sqlite3\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Conv2D, MaxPooling2D,concatenate, Flatten, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "SQL=SQLCalls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def process_img(original_image):\n",
    "    processed_img= cv2.resize(original_image,(580,580))\n",
    "    return np.array(np.transpose(processed_img,(0,1,2)))\n",
    "print_screen = np.array(ImageGrab.grab(bbox=(0,60,580,530)))\n",
    "print(print_screen.shape)\n",
    "x=process_img(print_screen)\n",
    "Image.fromarray(x,'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "epoch=0\n",
    "frame_count=0\n",
    "ACTION,WAIT,DEATH,GENERATION_OVER,RESTORE=0,1,2,3,4\n",
    "print(\"Taking picture of the top-left of the screen.\")\n",
    "print(\"Please check image to ensure it only displays the emulator.\")\n",
    "img=ImageGrab.grab(bbox=(0,60,580,530))\n",
    "img.save(\"../Test.png\")\n",
    "\n",
    "#Hyper Params\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .1 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "anneling_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 1024 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network\n",
    "img_size=84 #Size of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, '258 1000004 1.4357737968078')\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT GenomeNum,Gene,GeneContent FROM Genes ORDER BY Genome,Gene\")\n",
    "GenomesUnformatted=cur.fetchall()\n",
    "print(GenomesUnformatted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[205.0, 1000003.0, -1.933835871456]]\n",
      "[[339.0, 1000003.0, -1.3364055299539], [258.0, 1000004.0, 1.4357737968078], [178.0, 1000004.0, -1.9400616473891]]\n",
      "0 0 9 9\n",
      "-1.94006164739\n",
      "0 6 11 9\n",
      "1.43577379681\n"
     ]
    }
   ],
   "source": [
    "Genomes=SQL.GatherGenomes()\n",
    "POPULATION=len(Genomes)\n",
    "#print(POPULATION)\n",
    "#print(Genomes[0])\n",
    "batch_size = POPULATION//4 #How many experiences to use for each training step.\n",
    "BoxRadius=6\n",
    "BoxLength=BoxRadius*2+1\n",
    "BoxArea=(BoxLength)*(BoxLength)\n",
    "gene_image=np.empty([len(Genomes),BoxLength,BoxLength,12])\n",
    "gene_image.fill(0)\n",
    "BUTTON_AMOUNT=6\n",
    "print(Genomes[82])\n",
    "for Genome_Num,Genome in enumerate(Genomes):\n",
    "    if Genome_Num==0:\n",
    "        print(Genome)\n",
    "        for gene in Genome:\n",
    "            genome_type=0\n",
    "            if gene[0]<BoxArea:\n",
    "                pass\n",
    "                #Normal Input\")\n",
    "            elif gene[0]>BoxArea*2:\n",
    "                continue\n",
    "                #bias\n",
    "            else:\n",
    "                pass\n",
    "                #print(\"Inverse Input\")\n",
    "                genome_type+=BUTTON_AMOUNT\n",
    "            genome_type+=int(gene[1]-1000001) \n",
    "            if genome_type>=0:\n",
    "                # print X,Y,Type(Type of Input,Button Pressed)\n",
    "                gene_image[Genome_Num][int(gene[0]%(BoxArea)//BoxLength)][int(gene[0]%(BoxArea)%13)][genome_type]=gene[2]             \n",
    "'''\n",
    "[[    339 1000003       9]\n",
    " [    258 1000004       7]\n",
    " [    178 1000004       8]\n",
    "'''\n",
    "\n",
    "for l in range(6):\n",
    "    for i in range(len(gene_image[l])):\n",
    "        #print(gene_image[l][i])\n",
    "        for j in range(len(gene_image[l][i])):\n",
    "            for k in range(len(gene_image[l][i][j])):\n",
    "                if gene_image[l][i][j][k]!=0:\n",
    "                    print(l,i,j,k)\n",
    "                    print(gene_image[l][i][j][k])\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adapt_array(arr):\n",
    "    \"\"\"\n",
    "    http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "    \"\"\"\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(out.read())\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_genomes():\n",
    "    BoxRadius=6\n",
    "    BoxLength=BoxRadius*2+1\n",
    "    BoxArea=(BoxLength)\n",
    "    gene_image=np.empty([len(Genomes),BoxLength,BoxLength,12])\n",
    "    gene_image.fill(0)\n",
    "    BUTTON_AMOUNT=6\n",
    "    for Genome_Num,Genome in enumerate(Genomes):\n",
    "        for gene in Genome:\n",
    "            genome_type=0\n",
    "            if gene[0]>BoxLength:\n",
    "                pass\n",
    "                #print(\"Normal Input\")\n",
    "            if gene[1]>BoxLength:\n",
    "                pass\n",
    "                #print(\"Inverse Input\")\n",
    "                genome_type+=BUTTON_AMOUNT\n",
    "            genome_type+=int(gene[1]-1000001) \n",
    "            if genome_type>=0:\n",
    "                # print X,Y,Type(Type of Input,Button Pressed)\n",
    "                gene_image[Genome_Num][int(gene[0]%(BoxArea)//BoxArea)][int(gene[0]%(BoxArea)%13)][genome_type]=gene[2] \n",
    "    return gene_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x25089123960>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "\n",
    "# Converts TEXT to np.array when selecting\n",
    "sqlite3.register_converter(\"array\", convert_array)\n",
    "\n",
    "con=sqlite3.connect('DQN.db', detect_types=sqlite3.PARSE_DECLTYPES,isolation_level=None)\n",
    "cur = con.cursor()\n",
    "cur.execute(\"PRAGMA synchronous = OFF;\")\n",
    "cur.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "cur.execute(\"PRAGMA read_uncommitted = true;\")\n",
    "cur.execute(\"SELECT GenomeNum,Gene,GeneContent FROM Genes ORDER BY Genome,Gene\")\n",
    "# trainBatch=SQL.gain_history()\n",
    "# batch_size=20\n",
    "# trainBatch=trainBatch[0:batch_size]\n",
    "# time_stamp=datetime.datetime.now().time()\n",
    "# genomeImages=setup_genomes()\n",
    "# genomeImages=genomeImages[0:batch_size]\n",
    "# for i in range(len(genomeImages)):\n",
    "#     sql = ''' INSERT INTO example_genes\n",
    "#                (GenomeKey,GeneImage)\n",
    "#                VALUES\n",
    "#                (?,?)'''\n",
    "#     cur.execute(sql, (str(time_stamp)+str(i),genomeImages[i]))\n",
    "# con.commit()    \n",
    "# [0] Image\n",
    "# [1] GenomeNUm\n",
    "# [2] Score\n",
    "# [3] ImageEn d\n",
    "# states=trainBatch[:,0]\n",
    "# GenomeNum=trainBatch[:,1]\n",
    "# score=trainBatch[:,2]\n",
    "# states_after=trainBatch[:,3]\n",
    "# for i in range(len(trainBatch)):\n",
    "#     sql=''' INSERT INTO example_images\n",
    "#                (GenomeKey,Score,Image,ImageEnd)\n",
    "#                VALUES\n",
    "#                (?,?,?,?)'''\n",
    "#     cur.execute(sql, (states[i],GenomeNum[i],score[i],states_after[i]))\n",
    "# con.commit()  \n",
    "# sql=''' INSERT INTO example_timestamps\n",
    "#                 (timestamp)\n",
    "#                 VALUES\n",
    "#                 (?)'''\n",
    "# cur.execute(sql, (str(time_stamp),))\n",
    "# con.commit()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''Select image,score,imageEnd,geneImage,ei.GenomeKey,eg.GenomeKey\n",
    "        from example_images ei\n",
    "        inner join \n",
    "        example_genes eg on ei.genomeKey==eg.genomeKey\n",
    "        where score=-1 LIMIT 99'''\n",
    "cur.execute(sql)\n",
    "results=cur.fetchall()\n",
    "results=np.array(results)\n",
    "np.random.shuffle(results)\n",
    "sql = '''Select image,score,imageEnd,geneImage, ei.GenomeKey,eg.GenomeKey \n",
    "        from example_images ei\n",
    "        inner join \n",
    "        example_genes eg on ei.genomeKey==eg.genomeKey\n",
    "        where score=0 \n",
    "        LIMIT 99'''\n",
    "cur.execute(sql)\n",
    "results2=cur.fetchall()\n",
    "results2=np.array(results2)\n",
    "np.random.shuffle(results2)\n",
    "# sql = '''Select image\n",
    "#         from rewards\n",
    "#         where GenomeNum=1 LIMIT 5'''\n",
    "# cur.execute(sql)\n",
    "# results3=cur.fetchall()\n",
    "# results3=np.array(results3)\n",
    "# np.random.shuffle(results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_image (InputLayer)          (None, 580, 580, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 579, 579, 16)  208         main_image[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 578, 578, 16)  1040        conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 289, 289, 32)  544         conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 145, 145, 32)  1056        conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "gene_image (InputLayer)          (None, 13, 13, 12)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 49, 49, 8)     264         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 12, 12, 16)    784         gene_image[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 25, 25, 8)     72          conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 11, 11, 16)    1040        conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 5000)          0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1936)          0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 6936)          0           flatten_1[0][0]                  \n",
      "                                                                   flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 32)            221984      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 8)             264         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2)             18          dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 227,274\n",
      "Trainable params: 227,274\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    image_model_inputs = Input(shape=X[0].shape,dtype='float32',name='main_image')\n",
    "    image_model=Conv2D(16, (2, 2), padding='valid', activation='relu')(image_model_inputs)\n",
    "    image_model=Conv2D(16, (2, 2), padding='valid', activation='relu')(image_model)\n",
    "\n",
    "    image_model=Conv2D(32, (1,1),strides=2, padding='valid', activation='relu')(image_model)\n",
    "    image_model=Conv2D(32, (1,1),strides=2, padding='valid', activation='relu')(image_model)\n",
    "\n",
    "    image_model=Conv2D(8, (1,1),strides=3, padding='same', activation='relu')(image_model)\n",
    "    image_model=Conv2D(8, (1,1),strides=2, padding='same', activation='relu')(image_model)\n",
    "    \n",
    "    image_model=Flatten()(image_model)\n",
    "    \n",
    "    gene_model_inputs = Input(shape=X_gene[0].shape,dtype='float32',name='gene_image')\n",
    "    gene_model=Conv2D(16, (2, 2), padding='valid', activation='relu')(gene_model_inputs)\n",
    "    gene_model=Conv2D(16, (2, 2), padding='valid', activation='relu')(gene_model)\n",
    "    \n",
    "   # gene_model=Conv2D(8, (1,1),strides=3, padding='same', activation='relu')(gene_model)\n",
    "    #gene_model=Conv2D(8, (1,1),strides=2, padding='same', activation='relu')(gene_model)\n",
    "    \n",
    "    gene_model=Flatten()(gene_model)\n",
    "    \n",
    "    combined_model=concatenate([image_model,gene_model])\n",
    "    \n",
    "    combined_model=Dense(32, activation='relu')(combined_model)\n",
    "    combined_model=Dense(8, activation='relu')(combined_model)\n",
    "    combined_model_preditions=Dense(2, activation='softmax')(combined_model)\n",
    "    model=Model(inputs=[image_model_inputs,gene_model_inputs],outputs=combined_model_preditions)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "K.clear_session()\n",
    "X=np.reshape(np.vstack(np.concatenate((results[:,0],results2[:,0]))),(-1,580,580,3))\n",
    "X_gene=np.reshape(np.vstack(np.concatenate((results[:,3],results2[:,3]))),(-1,13,13,12))\n",
    "Y=np.vstack(np.concatenate((results[:,1],results2[:,1])))\n",
    "Y = to_categorical(Y, num_classes=2)\n",
    "train=170\n",
    "y_train=Y[:train]\n",
    "y_test=Y[train:]\n",
    "x_train=X[:train]\n",
    "x_test=X[train:]\n",
    "x_gene_train=X_gene[:train]\n",
    "x_gene_test=X_gene[train:]\n",
    "model = make_model()\n",
    "plot_model(model, to_file='multilayer_perceptron_graph.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05:54:39.08542826\n",
      "05:43:18.1571557\n",
      "2.16 -1.47 -2.03 0.59 0.96 -1.17 -0.47 1.63 1.10 -0.56 1.09 -1.14 -1.98 1.29 -2.02 1.70 0.82 -0.05 -1.98 0.34 1.58 1.09 0.80 1.12 1.75 -0.29 1.56 "
     ]
    }
   ],
   "source": [
    "print(results2[:,4][0])\n",
    "print(results2[:,4][1])\n",
    "#Image.fromarray(results2[:,0][0],'RGB')\n",
    "Image.fromarray(results3[:,0][0],'RGB')\n",
    "gene=results2[:,3][0]\n",
    "#gene=gene_image[52]\n",
    "for row in gene:\n",
    "    for col in row:\n",
    "        #print(col)\n",
    "        for button in col:\n",
    "            pass\n",
    "            if button!=0.0: \n",
    "                print(\"{0:.2f}\".format(button),end=' ')\n",
    "       # print(\" \")    \n",
    "    #print(\" \")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 28 samples\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 3s - loss: 0.2537 - acc: 0.9118 - val_loss: 0.6384 - val_acc: 0.8571\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 3s - loss: 0.2649 - acc: 0.9176 - val_loss: 0.2283 - val_acc: 0.8929\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 3s - loss: 0.2640 - acc: 0.8824 - val_loss: 0.3091 - val_acc: 0.9286\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 3s - loss: 0.1496 - acc: 0.9529 - val_loss: 0.3976 - val_acc: 0.9286\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 3s - loss: 0.1189 - acc: 0.9588 - val_loss: 0.2631 - val_acc: 0.9643\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 3s - loss: 0.1631 - acc: 0.9235 - val_loss: 0.3132 - val_acc: 0.9643\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 3s - loss: 0.0766 - acc: 0.9588 - val_loss: 0.3365 - val_acc: 0.9286\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 3s - loss: 0.0489 - acc: 0.9882 - val_loss: 0.3521 - val_acc: 0.9643\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 3s - loss: 0.1093 - acc: 0.9471 - val_loss: 0.3507 - val_acc: 0.9643\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 3s - loss: 0.1048 - acc: 0.9588 - val_loss: 0.4981 - val_acc: 0.8929\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 3s - loss: 0.0582 - acc: 0.9824 - val_loss: 0.2605 - val_acc: 0.9643\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 3s - loss: 0.0349 - acc: 0.9941 - val_loss: 0.3883 - val_acc: 0.9286\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 3s - loss: 0.0361 - acc: 0.9941 - val_loss: 0.3778 - val_acc: 0.9286\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 3s - loss: 0.0346 - acc: 0.9882 - val_loss: 0.4130 - val_acc: 0.9286\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 3s - loss: 0.0283 - acc: 0.9824 - val_loss: 0.4109 - val_acc: 0.9286\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 3s - loss: 0.0142 - acc: 1.0000 - val_loss: 0.4308 - val_acc: 0.9286\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 3s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5497 - val_acc: 0.9286\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 3s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.4531 - val_acc: 0.9286\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 3s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4781 - val_acc: 0.9286\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 3s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5327 - val_acc: 0.9286\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "batch_size=16\n",
    "history = model.fit([x_train,x_gene_train], y_train, batch_size=batch_size, epochs=epochs, verbose=1,validation_data=([x_test,x_gene_test], y_test))\n",
    "\n",
    "#model1.evaluate(test_data, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27957120537757874, 1.0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 16)        784       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 8)           136       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 8)           72        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 3,370\n",
      "Trainable params: 3,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-3e8aa0803eeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m130\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'multilayer_perceptron_graph.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \"\"\"\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (2, 2), padding='valid', activation='relu', input_shape=X[0].shape))\n",
    "    model.add(Conv2D(16, (2, 2), padding='valid', activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Conv2D(8, (1, 1),strides=3, padding='same', activation='relu'))\n",
    "    model.add(Conv2D(8, (1, 1),strides=2, activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "K.clear_session()\n",
    "X=np.reshape(np.vstack(np.concatenate((results[:,3],results2[:,3]))),(-1,13,13,12))\n",
    "np.random.shuffle(X)\n",
    "Y=np.vstack(np.concatenate((results[:,1],results2[:,1])))\n",
    "Y = to_categorical(Y, num_classes=2)\n",
    "np.random.shuffle(Y)\n",
    "y_train=Y[0:130]\n",
    "y_test=Y[130:150]\n",
    "x_train=X[0:130]\n",
    "x_test=X[130:150]\n",
    "model = make_model()\n",
    "plot_model(model, to_file='multilayer_perceptron_graph.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
